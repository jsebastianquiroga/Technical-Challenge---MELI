{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leer datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      4\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/items_titles.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/Estudio/MAIN/GIT/Technical-Challenge---MELI/meli/lib/python3.10/site-packages/pandas/__init__.py:37\u001b[0m\n\u001b[1;32m     30\u001b[0m     _module \u001b[38;5;241m=\u001b[39m _err\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC extension: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_module\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not built. If you want to import \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     33\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpandas from the source directory, you may need to run \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpython setup.py build_ext\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to build the C extensions first.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     35\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m_err\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     38\u001b[0m     get_option,\n\u001b[1;32m     39\u001b[0m     set_option,\n\u001b[1;32m     40\u001b[0m     reset_option,\n\u001b[1;32m     41\u001b[0m     describe_option,\n\u001b[1;32m     42\u001b[0m     option_context,\n\u001b[1;32m     43\u001b[0m     options,\n\u001b[1;32m     44\u001b[0m )\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# let init-time option registration happen\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig_init\u001b[39;00m  \u001b[38;5;66;03m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Estudio/MAIN/GIT/Technical-Challenge---MELI/meli/lib/python3.10/site-packages/pandas/_config/__init__.py:20\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mpandas._config is considered explicitly upstream of everything else in pandas,\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mshould have no intra-pandas dependencies.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;03mare initialized.\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      8\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdetect_console_encoding\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn_copy_on_write\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     19\u001b[0m ]\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dates  \u001b[38;5;66;03m# pyright: ignore[reportUnusedImport]  # noqa: F401\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     23\u001b[0m     _global_config,\n\u001b[1;32m     24\u001b[0m     describe_option,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     29\u001b[0m     set_option,\n\u001b[1;32m     30\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/Estudio/MAIN/GIT/Technical-Challenge---MELI/meli/lib/python3.10/site-packages/pandas/_config/config.py:72\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_typing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     69\u001b[0m     F,\n\u001b[1;32m     70\u001b[0m     T,\n\u001b[1;32m     71\u001b[0m )\n\u001b[0;32m---> 72\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_exceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m find_stack_level\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mabc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     76\u001b[0m         Generator,\n\u001b[1;32m     77\u001b[0m         Iterable,\n\u001b[1;32m     78\u001b[0m     )\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1006\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:688\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:879\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:975\u001b[0m, in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1074\u001b[0m, in \u001b[0;36mget_data\u001b[0;34m(self, path)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('../data/items_titles.csv')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "\n",
    "# Función para limpiar el texto\n",
    "def preprocess_text(text):\n",
    "    # Convertir a minúsculas\n",
    "    text = text.lower()\n",
    "    # Eliminar acentos\n",
    "    text = ''.join(\n",
    "        char for char in unicodedata.normalize('NFKD', text) if not unicodedata.combining(char)\n",
    "    )\n",
    "    return text\n",
    "\n",
    "# Aplicar la limpieza a la columna 'ITE_ITEM_TITLE'\n",
    "df['cleaned_title'] = df['ITE_ITEM_TITLE'].apply(preprocess_text)\n",
    "\n",
    "# Mostrar los primeros resultados\n",
    "print(\"Primeros registros después de la limpieza:\")\n",
    "print(df[['ITE_ITEM_TITLE', 'cleaned_title']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Función para tokenizar con eliminación de puntuación\n",
    "def tokenize_with_re(text):\n",
    "    # Dividir en palabras ignorando puntuación\n",
    "    return re.findall(r'\\b\\w+\\b', text)\n",
    "\n",
    "# Aplicar tokenización con re\n",
    "df['tokens'] = df['cleaned_title'].apply(tokenize_with_re)\n",
    "\n",
    "# Mostrar los primeros resultados\n",
    "print(\"Primeros registros después de la tokenización:\")\n",
    "print(df[['cleaned_title', 'tokens']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se identifica que los productos están en portugués."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Unir todas las palabras en una lista\n",
    "all_words = [word for tokens in df['tokens'] for word in tokens]\n",
    "\n",
    "# Contar la frecuencia de cada palabra\n",
    "word_counts = Counter(all_words)\n",
    "\n",
    "# Obtener las 10 palabras más frecuentes\n",
    "most_common_words = word_counts.most_common(10)\n",
    "\n",
    "print(\"Palabras más frecuentes:\")\n",
    "print(most_common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams\n",
    "\n",
    "# Función para generar n-gramas\n",
    "def generate_ngrams(tokens, n):\n",
    "    return list(ngrams(tokens, n))\n",
    "\n",
    "# Crear n-gramas (bi-gramas y tri-gramas)\n",
    "df['bigrams'] = df['tokens'].apply(lambda x: generate_ngrams(x, 2))\n",
    "df['trigrams'] = df['tokens'].apply(lambda x: generate_ngrams(x, 3))\n",
    "\n",
    "# Contar los bigramas más comunes\n",
    "all_bigrams = [bigram for bigrams in df['bigrams'] for bigram in bigrams]\n",
    "bigram_counts = Counter(all_bigrams)\n",
    "\n",
    "# Contar los trigramas más comunes\n",
    "all_trigrams = [trigram for trigrams in df['trigrams'] for trigram in trigrams]\n",
    "trigram_counts = Counter(all_trigrams)\n",
    "\n",
    "print(\"Bigrams más frecuentes:\")\n",
    "print(bigram_counts.most_common(10))\n",
    "\n",
    "print(\"Trigrams más frecuentes:\")\n",
    "print(trigram_counts.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Longitud de cada título\n",
    "df['num_tokens'] = df['tokens'].apply(len)\n",
    "\n",
    "# Estadísticas descriptivas\n",
    "mean_tokens = df['num_tokens'].mean()\n",
    "max_tokens = df['num_tokens'].max()\n",
    "min_tokens = df['num_tokens'].min()\n",
    "\n",
    "print(f\"Longitud promedio de tokens por título: {mean_tokens:.2f}\")\n",
    "print(f\"Longitud máxima: {max_tokens}\")\n",
    "print(f\"Longitud mínima: {min_tokens}\")\n",
    "\n",
    "# Graficar la distribución de la longitud\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df['num_tokens'], bins=20, color='skyblue', edgecolor='black')\n",
    "plt.title(\"Distribución de la longitud de tokens por título\")\n",
    "plt.xlabel(\"Número de tokens\")\n",
    "plt.ylabel(\"Frecuencia\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Convertir los tokens a texto limpio nuevamente\n",
    "df['cleaned_text'] = df['tokens'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# Crear la matriz TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(df['cleaned_text'])\n",
    "\n",
    "# Obtener palabras clave con TF-IDF más alto para el primer título\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "tfidf_scores = tfidf_matrix[0].T.todense().tolist()\n",
    "keywords = [(feature_names[i], score[0]) for i, score in enumerate(tfidf_scores) if score[0] > 0]\n",
    "keywords = sorted(keywords, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"Palabras clave para el primer título según TF-IDF:\")\n",
    "print(keywords[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de Títulos:\n",
    "\n",
    "1. **Palabras más frecuentes**:\n",
    "   - Identificar términos comunes como `tenis` (22,600 apariciones) o `feminino` (7,931) nos permite detectar patrones generales en los productos.\n",
    "   - Estas palabras frecuentes pueden no ser útiles directamente para medir similitud, ya que están presentes en muchos títulos, pero ayudan a filtrar palabras no relevantes.\n",
    "\n",
    "2. **Bigramas y Trigramas más frecuentes**:\n",
    "   - Frases clave como `tenis feminino casual` y `bicicleta aro 29` destacan categorías y características específicas de los productos.\n",
    "   - Estas combinaciones pueden ser valiosas para crear representaciones más específicas de los títulos y mejorar la detección de similitudes.\n",
    "\n",
    "3. **Estadísticas descriptivas**:\n",
    "   - La longitud promedio de 7.26 tokens por título indica que los textos son concisos, lo que favorece la eficiencia al calcular similitudes.\n",
    "   - Las longitudes máxima y mínima (28 y 1 tokens, respectivamente) sugieren la necesidad de manejar casos extremos, como títulos muy cortos o detallados, en la comparación.\n",
    "\n",
    "4. **Palabras clave según TF-IDF**:\n",
    "   - Términos con altos puntajes como `posh` y `ascension` indican elementos únicos que pueden ser cruciales para identificar productos similares.\n",
    "   - Palabras con puntajes bajos (`tenis`, `masculino`) son menos útiles para diferenciar productos.\n",
    "\n",
    "**Conclusión (En el contexto del reto)**:\n",
    "- Este análisis permite priorizar características clave de los títulos (e.g., bigramas y trigramas únicos) para calcular similitudes entre productos.\n",
    "- El uso de TF-IDF es una opción viable para representar títulos y calcular similitudes basadas en coseno o distancias.\n",
    "- La eficiencia en tiempo de ejecución dependerá de optimizaciones en el algoritmo y la elección de estructuras de datos escalables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eliminar Stop-words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "# Descargar stop words si no están disponibles\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Combinar stop words en portugués\n",
    "stop_words_pt = set(stopwords.words('portuguese'))\n",
    "\n",
    "\n",
    "# Función para eliminar stop words de múltiples idiomas\n",
    "def remove_multilang_stopwords(tokens):\n",
    "    return [word for word in tokens if word not in stop_words_pt]\n",
    "\n",
    "# Aplicar la función a los tokens\n",
    "df['filtered_tokens'] = df['tokens'].apply(remove_multilang_stopwords)\n",
    "\n",
    "# Verificar resultados\n",
    "print(\"Primeros registros sin stop words:\")\n",
    "print(df[['tokens', 'filtered_tokens']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparar longitud antes y después de eliminar stop words\n",
    "df['original_length'] = df['tokens'].apply(len)\n",
    "df['filtered_length'] = df['filtered_tokens'].apply(len)\n",
    "\n",
    "# Calcular palabras eliminadas\n",
    "df['removed_words'] = df['original_length'] - df['filtered_length']\n",
    "\n",
    "# Estadísticas descriptivas\n",
    "average_removed = df['removed_words'].mean()\n",
    "percentage_reduction = (average_removed / df['original_length'].mean()) * 100\n",
    "\n",
    "# Mostrar resultados\n",
    "print(f\"Promedio de palabras eliminadas: {average_removed:.2f}\")\n",
    "print(f\"Porcentaje de reducción en el tamaño de los tokens: {percentage_reduction:.2f}%\")\n",
    "\n",
    "# Distribución de palabras eliminadas\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df['removed_words'], bins=20, color='skyblue', edgecolor='black')\n",
    "plt.title(\"Distribución de palabras eliminadas por título\")\n",
    "plt.xlabel(\"Número de palabras eliminadas\")\n",
    "plt.ylabel(\"Frecuencia\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Justificación para la eliminación de Stop Words\n",
    "\n",
    "1. **Reducción de ruido semántico**:\n",
    "   - Las stop words, como \"de\", \"para\", \"e\" (en portugués), son palabras comunes que no aportan información significativa para identificar similitudes entre productos.\n",
    "   - Su presencia puede generar relaciones artificiales entre títulos que comparten conectores pero no son realmente similares.\n",
    "\n",
    "2. **Foco en términos clave**:\n",
    "   - Al eliminar las stop words, el análisis se concentra en palabras relevantes como nombres de productos, categorías, y características distintivas.\n",
    "   - Esto mejora la precisión al identificar títulos con contenido semántico significativo.\n",
    "\n",
    "3. **Minimización de similitudes irreales**:\n",
    "   - Títulos como `\"Tenis de homem\"` y `\"Bicicleta para mulher\"` comparten la palabra \"para\", pero no tienen relación real. Al eliminar este tipo de palabras, evitamos asociaciones incorrectas.\n",
    "\n",
    "4. **Impacto controlado**:\n",
    "   - Aunque la eliminación de stop words reduce el tamaño de los tokens en solo un **5.18%**, elimina un promedio de **0.38 palabras por título**, lo que ayuda a reducir ruido sin afectar significativamente el contenido útil.\n",
    "\n",
    "**Conclusión**:\n",
    "- La eliminación de stop words es una estrategia clave para mejorar la precisión en la identificación de similitudes entre productos, al enfocarse en términos que realmente definen la relación entre ellos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar títulos que contengan \"para\" o \"de\"\n",
    "filtered_examples = df[df['tokens'].apply(lambda x: 'para' in x or 'de' in x)]\n",
    "\n",
    "# Mostrar algunos ejemplos\n",
    "print(\"Ejemplos de títulos con 'para' o 'de':\")\n",
    "print(filtered_examples[['ITE_ITEM_TITLE', 'tokens']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validación de la hipótesis: Minimización de similitudes irreales\n",
    "\n",
    "**Ejemplos analizados**:\n",
    "- Títulos con palabras comunes como \"para\" o \"de\" incluyen:\n",
    "  - `\"Tenis Para Caminhada Super Levinho Spider Corrida\"`\n",
    "  - `\"Sapatilha Bike Absolute Nero Mtb Para Pedal Clip\"`\n",
    "  - `\"Tenis Feminino De Fazer Caminhada Corrida Academia\"`\n",
    "  - `\"Tenis Sneacker Feminino Surfista Cheia De Marca\"`\n",
    "  - `\"Tenis De Menino Bota Com Luz De Led Sapato Preto\"`\n",
    "\n",
    "**Observaciones**:\n",
    "1. **Patrón recurrente de conectores comunes**:\n",
    "   - Palabras como \"para\" y \"de\" aparecen en múltiples títulos, sin aportar información semántica relevante.\n",
    "   - Ejemplo: `\"Tenis Para Caminhada\"` y `\"Bicicleta Para Mulher\"` comparten \"para\", pero representan productos completamente diferentes.\n",
    "\n",
    "2. **Ruido en la similitud**:\n",
    "   - La presencia de estas palabras puede llevar a similitudes artificiales entre títulos que no tienen una relación real, al estar basadas únicamente en palabras comunes.\n",
    "\n",
    "**Conclusión**:\n",
    "Eliminar palabras comunes como \"para\" y \"de\" mejora la precisión al calcular similitudes entre productos, al reducir el ruido semántico y enfocar el análisis en términos clave."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorización, similitud usando TF-IDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Unir tokens en un solo texto para cada título\n",
    "df['filtered_text'] = df['filtered_tokens'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# Crear la matriz TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(df['filtered_text'])\n",
    "\n",
    "print(\"Matriz TF-IDF generada con forma:\", tfidf_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from itertools import combinations\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "def calculate_similarity(pair, cosine_sim, df):\n",
    "    \"\"\"\n",
    "    Calcula la similitud de coseno para un par de índices.\n",
    "\n",
    "    Args:\n",
    "        pair (tuple): Tupla con los índices de los textos a comparar.\n",
    "        cosine_sim (ndarray): Matriz de similitud de coseno.\n",
    "        df (pd.DataFrame): DataFrame original con los textos.\n",
    "\n",
    "    Returns:\n",
    "        list: Lista con los títulos y su puntaje de similitud.\n",
    "    \"\"\"\n",
    "    i, j = pair\n",
    "    title1 = df.iloc[i]['ITE_ITEM_TITLE']\n",
    "    title2 = df.iloc[j]['ITE_ITEM_TITLE']\n",
    "    score = cosine_sim[i, j]\n",
    "    return [title1, title2, score]\n",
    "\n",
    "# Calcular la matriz de similitud\n",
    "cosine_sim = cosine_similarity(tfidf_matrix)\n",
    "\n",
    "# Crear combinaciones únicas de índices\n",
    "pairs = list(combinations(range(len(df)), 2))\n",
    "\n",
    "# Paralelizar el cálculo de similitudes\n",
    "results = Parallel(n_jobs=-1)(delayed(calculate_similarity)(pair, cosine_sim, df) for pair in pairs)\n",
    "\n",
    "# Crear el DataFrame final con los resultados\n",
    "similarity_df = pd.DataFrame(results, columns=['ITE_ITEM_TITLE_1', 'ITE_ITEM_TITLE_2', 'Score Similitud'])\n",
    "\n",
    "# Ordenar por el puntaje de similitud en orden descendente\n",
    "similarity_df = similarity_df.sort_values(by='Score Similitud', ascending=False)\n",
    "\n",
    "# Mostrar los primeros resultados\n",
    "print(similarity_df.head())\n",
    "\n",
    "# Guardar los resultados en un archivo.\n",
    "similarity_df.to_csv('../data/output/similarities_output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Función para medir el tiempo de ejecución\n",
    "def measure_execution_time(tfidf_matrix):\n",
    "    start_time = time.time()\n",
    "    cosine_similarity(tfidf_matrix)\n",
    "    end_time = time.time()\n",
    "    return end_time - start_time\n",
    "\n",
    "# Evaluar en diferentes tamaños del dataset\n",
    "sizes = [100, 500, 1000, len(df)]\n",
    "times = []\n",
    "\n",
    "for size in sizes:\n",
    "    sample_matrix = tfidf_matrix[:size, :]\n",
    "    exec_time = measure_execution_time(sample_matrix)\n",
    "    times.append((size, exec_time))\n",
    "\n",
    "# Mostrar los tiempos\n",
    "print(\"Tiempos de ejecución:\")\n",
    "for size, exec_time in times:\n",
    "    print(f\"Tamaño: {size} - Tiempo: {exec_time:.4f} segundos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts/similarity import TextSimilarityPipeline\n",
    "\n",
    "# Crear instancia y ejecutar\n",
    "similitud = TextSimilarityPipeline(df)\n",
    "resultado = similitud.run_pipeline()\n",
    "\n",
    "# Mostrar resultado\n",
    "resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meli",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
